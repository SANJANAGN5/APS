---
title: "Secondlabtry.Rmd"
output: html_document
date: "2025-09-29"
---
step1:Bernoulli Random Variables and Majority Output
```{r}
X=vector("numeric",length=10)
for (i in 1:10){
  X[i]=rbinom(1,1,0.8)
}
print(X)
sm=mean(X)
if(sm>0.5){
  print(1)
}else{
  print(0)
}
  
```
2. Repeating Bernoulli Majority Output 10,000 Times
```{r}
ccount=0
for(j in 1:10000){
  X=vector("numeric",length=10)
for (i in 1:10){
  X[i]=rbinom(1,1,0.8)
}
sm=mean(X)
if(sm>0.5){
  ccount = ccount + 1
}
}
acc=ccount/10000
print(acc)
```
Loading the Iris Dataset and Encoding Classes
```{r}
library(rpart)
df = read.csv("C:/Users/MSIS/Downloads/iris.csv")
nr=nrow(df)
mclass=vector("numeric",length=nr)
for(i in 1:nr){
  if(df[i,5]=="setosa"){
    mclass[i]=0
  }else if(df[i,5]=='virginica'){
    mclass[i]=1
  }else{
    mclass[i]=2
  }
}
df=cbind(df, mclass)
head(df)
```



3.Splitting Data and Training a Decision Tree
```{r}
s=sample(x=1:nr,size=0.2*nr,replace=FALSE)
train=df[s,-5]
test=df[-s,-5]
mfit=rpart(mclass~.,data=train,method="class")
library(rpart.plot)
rpart.plot(mfit)
```
Evaluating Train and Test Accuracy
```{r}
ypredtrain=predict(mfit,newdata=train,type="class")
ypredtest=predict(mfit,newdata=test,type="class")
trainacc=mean(train[,5]==ypredtrain)
testacc=mean(test[,5]==ypredtest)
print(trainacc)
print(testacc)
```
4. Bagging: Training Multiple Trees on Random Subsets

```{r}
ntrees=10
vtrainacc=vector("numeric", length=ntrees)
vtestacc=vector("numeric", length=ntrees)
forest=vector("list", length=ntrees)
for(i in 1:ntrees){
s=sample(x=1:nr,size=0.2*nr,replace=FALSE)
train=df[s,-5]
test=df[-s,-5]
mfit=rpart(mclass~.,data=train,method="class")
forest[i]=list(mfit=mfit)
ypredtrain=predict(mfit, newdata=train,type="class")
ypredtest=predict(mfit,newdata=test,type="class")
vtrainacc[i]=mean(train[,5]==ypredtrain)
vtestacc[i]=mean(test[,5]==ypredtest)
}
print(vtrainacc)
print(vtestacc)
```


```{r}

sntrain=data.frame(C(1:30))
sntest=data.frame(C(1:120))
for(j in 1:ntrees){
  ypredtrain=predict(forest[[j]],newdata=train,type="class")
  ypredtest=predict(forest[[j]],newdata=test,type="class")
  sntrain=cbind(sntrain,ypredtrain)
  sntest=cbind(sntest,ypredtest)
}
print(sntrain)
print(sntest)
```


```{r}
library(DescTools)
get_value=function(x){
  sm=Mode(x)
  if(length(sm)==1){
    return(sm)
  }else{
    return(sm[1])
  }
}
fypredtrain=apply(sntrain[,2:11],1,get_value)
fypredtest=apply(sntest[,2:11],1,get_value)
fytrainacc=mean(train[,5]==fypredtrain)
fytestacc=mean(test[,5]==fypredtest)
print(fytrainacc)
print(fytestacc)
```


5.
```{r}
set.seed(123)
ntrees = 6
nfeatures = 2

features = colnames(df)[1:4]

forest = vector("list", ntrees)
vtrainacc = vector("numeric", ntrees)
vtestacc = vector("numeric", ntrees)


for(i in 1:ntrees){
  selected_features = sample(features, nfeatures)
  formula = as.formula(paste("mclass ~", paste(selected_features, collapse = "+")))
  model = rpart(formula, data=train, method="class")
  forest[[i]] = model
  
  ypredtrain = predict(model, train, type="class")
  ypredtest = predict(model, test, type="class")
  
  vtrainacc[i] = mean(train$mclass == ypredtrain)
  vtestacc[i] = mean(test$mclass == ypredtest)
}

sntrain = data.frame(1:nrow(train))
sntest = data.frame(1:nrow(test))

for(j in 1:ntrees){
  sntrain = cbind(sntrain, predict(forest[[j]], train, type="class"))
  sntest = cbind(sntest, predict(forest[[j]], test, type="class"))
}

get_value = function(x){
  sm = Mode(x)
  if(length(sm) == 1) sm else sm[1]
}

fypredtrain = apply(sntrain[, 2:(ntrees+1)], 1, get_value)
fypredtest = apply(sntest[, 2:(ntrees+1)], 1, get_value)

fytrainacc = mean(train$mclass == fypredtrain)
fytestacc = mean(test$mclass == fypredtest)

print(vtrainacc)
print(vtestacc)
print(fytrainacc)
print(fytestacc)
```


